{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e90971",
   "metadata": {},
   "source": [
    "â”‚   â”‚     â€¢ Tokenize & convert to integer sequences  \n",
    "â”‚   â”‚     â€¢ Build a simple 1D-CNN (Embedding â†’ Conv1D â†’ GlobalMaxPool â†’ Dense)  \n",
    "â”‚   â”‚     â€¢ Train, plot loss/accuracy curves  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9db6dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 1. Load data\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(\"../data/processed/train.csv\")\n",
    "    test_df = pd.read_csv(\"../data/processed/test.csv\")\n",
    "\n",
    "    # Combine headline and short description\n",
    "    train_df[\"combined_text\"] = train_df[\"headline\"].fillna('') + \" \" + train_df[\"short_description\"].fillna('')\n",
    "    test_df[\"combined_text\"] = test_df[\"headline\"].fillna('') + \" \" + test_df[\"short_description\"].fillna('')\n",
    "\n",
    "    # Remove rows with empty combined_text\n",
    "    train_df = train_df[train_df[\"combined_text\"].str.strip() != \"\"]\n",
    "    test_df = test_df[test_df[\"combined_text\"].str.strip() != \"\"]\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_df[\"category\"])\n",
    "    y_test = le.transform(test_df[\"category\"])\n",
    "\n",
    "    return train_df[\"combined_text\"], test_df[\"combined_text\"], y_train, y_test, le\n",
    "\n",
    "train_texts, test_texts, y_train, y_test, le = load_data()\n",
    "\n",
    "# 2. Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_texts)\n",
    "X_test = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "# Pad sequences to ensure uniform length for CNN input\n",
    "X_train = pad_sequences(X_train, maxlen=200)  # You can adjust maxlen based on your dataset\n",
    "X_test = pad_sequences(X_test, maxlen=200)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the 1D CNN Model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding Layer\n",
    "model.add(Embedding(input_dim=10000, output_dim=128))  # Using 10000 words, embedding size of 128\n",
    "\n",
    "# Convolutional Layer\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))  # 128 filters, kernel size of 5\n",
    "\n",
    "# GlobalMaxPooling Layer\n",
    "model.add(GlobalMaxPooling1D())  # Reduces dimensionality by keeping max feature\n",
    "\n",
    "# Fully Connected (Dense) Layer\n",
    "model.add(Dense(128, activation='relu'))  # Dense layer with 128 units\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))  # Output layer with the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Plot loss and accuracy curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Predict class probabilities\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Convert one-hot to class labels\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"ðŸ“Œ CNN\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def51928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
